{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install colab dependencies, if you are running this script on your machine, please build a new conda enviroment\n",
    "# and install the dependices marked at requirements.txt\n",
    "!conda install gxx_linux-64 gcc_linux-64 swig\n",
    "!pip install -r requirements.txt\n",
    "import smac\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handout session1- Bayesian Optimization\n",
    "\n",
    "\n",
    "In this handout session, we will focus on a simple yet important application of BO for deep learning: tunning the learning rate of a deep neural network. It is highly recommended to learn a bit about Bayesian Optimization from the [MOOC](https://ki-campus.org/node/109) to better understand the concepts and methods discussed in the following sections.\n",
    "\n",
    "First, let's see how learning rates influence the performance of a neural network. We first create a simple network that will be trained on [KMNIST](https://github.com/rois-codh/kmnist) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim\n",
    "from typing import List, Any\n",
    "import typing\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from func_eval import LeNet_Evaluator\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "dataset_path = os.path.join('tmp', 'dataset')\n",
    "# you need to specify your device (cpu or cuda) here.\n",
    "device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Class \"LeNet_Evaluator\" is a helper class that allows you to evaluate a configuration without knowing the details of training a neural network. The most import functions that will be used in this exercise are `__init__` and `eval_config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(LeNet_Evaluator.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(LeNet_Evaluator.eval_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are creating an evaluator object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = LeNet_Evaluator(dataset_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An AutoML system needs to know what it optimizes for. A configuration space contains all the possible hyperparameters that an AutoML system can evaluate. Here we use the package [ConfigSpace](https://automl.github.io/ConfigSpace/master/index.html) to manage our configuration space. ConfigSpace allows us to define different sorts of hyperparameters that need to be optimized in AutoML problems. The values that these hyperparameters take can be of different types. Here, we restrict the space by considering Float and Integer values sampled from a unifrom distribution, which is imported through [UniformFloatHyperparameter](https://automl.github.io/ConfigSpace/master/API-Doc.html#ConfigSpace.hyperparameters.UniformFloatHyperparameter) and [UniformIntegerHyperparameter](https://automl.github.io/ConfigSpace/master/API-Doc.html#ConfigSpace.hyperparameters.UniformIntegerHyperparameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ConfigSpace import ConfigurationSpace, Configuration\n",
    "from ConfigSpace.hyperparameters import UniformFloatHyperparameter, UniformIntegerHyperparameter, Constant\n",
    "\n",
    "# we build a configuration space from which a configuration could be sampled \n",
    "cs_lenet = ConfigurationSpace(seed=1)\n",
    "\n",
    "batch_size = UniformIntegerHyperparameter('batch_size', lower=32, upper=1024, default_value=512, log=True)\n",
    "learning_rate = UniformFloatHyperparameter('learning_rate', lower=1e-4, upper=1., default_value=1e-2, log=True)\n",
    "\n",
    "cs_lenet.add_hyperparameters([batch_size, learning_rate])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first evaluate the hyperparameteres with a manually selected hyperparameter configuration. You could select the hyperparameter configuration that you believe optimal for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO select the corresponding hyperparameter values and store them as a dictionary\n",
    "hps_values_hand_tuned = {'batch_size': 128,\n",
    "                        'learning_rate': 1e-4}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the hand-tuned values and store them as a Configuration space object. We then evaluate this configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a Configuration object \n",
    "cfg_hand_tunned = Configuration(configuration_space=cs_lenet, values=hps_values_hand_tuned)\n",
    "val_score_hand_tunned = evaluator.eval_config(cfg_hand_tunned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SMAC to do hyperparameter optimization\n",
    "\n",
    "\n",
    "[SMAC](https://github.com/automl/SMAC3) is a tool for algorithm configuration to optimize the parameters of arbitrary algorithms, including hyperparameter optimization of Machine Learning algorithms. SMAC also supports more advanced hyperparameter optimization technique such as multi-fidelity optimization process. Please follow the [examples](https://github.com/automl/SMAC3/tree/master/examples/python) and optimize the batch size and learning rate with SMAC for 50 evaluations and compare the reuslt with a hand-tuned configuration (if appliable). You could use the facade [SMAC4HPO](https://github.com/automl/SMAC3/blob/master/examples/python/svm_cv.py) or [SMAC4MF](https://github.com/automl/SMAC3/blob/master/examples/python/mlp_mf.py) \n",
    "\n",
    "Doing a full HPO loop might take too much time (around 1.5 hours). If you successfully implemented this section, you could simply let this script run on the backend and continue the following exercises.\n",
    "\n",
    "Hint: `SMAC4HPO` usually requires one input : `cfg`. You could use `functools.partial` to specify other inputs. However, `SMAC4MF` requires `budget` as well.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO optimize the batch size and learning rate with SMAC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# (Optional) Using DEHB to do hyperparameter optimization\n",
    "\n",
    "Alternative to SMAC, [DEHB](https://github.com/automl/DEHB) is yet another scalable, robust and efficient hyperparameter optimization. Please follow the [examples](https://github.com/automl/DEHB/blob/master/examples/02_using%20DEHB_without_ConfigSpace.ipynb) and optimize the batch size and learning rate with DEHB for 3600 seconds and compare the reuslt with SMAC (if appliable). As before, you could simply let this script run on the backend and continue the following exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We create a wrapper for DEHB here\n",
    "import time\n",
    "def dehb_wrapper_eval_configuration(cfg, budget):\n",
    "    start_time = time.time()\n",
    "    res = evaluator.eval_config(cfg=cfg, budget=budget)\n",
    "    cost = time.time() - start_time\n",
    "    result = {\n",
    "        \"fitness\": res,  # DE/DEHB minimizes\n",
    "        \"cost\": cost,\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Since DEHB does not provide a setup.py file, you need to manually export the path of DEHB to PYTHONPATH:\n",
    "import sys\n",
    "import os\n",
    "from functools import partial\n",
    "dehb_path = './DEHB'\n",
    "os.environ['PATH'] += ':'+dehb_path\n",
    "from functools import partial\n",
    "\n",
    "from dehb import DEHB\n",
    "\n",
    "# TODO use DEHB to optimize the 2 hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As we would expect, we could probably do better by further manually tunning these hyperparameters. Let's automate the tunning process with Bayesian Optimization (BO).\n",
    "\n",
    "BO is an iterative algorithm that works as follows: \n",
    "- It first fits a probability model ([surrogate model](#Surrogate-Model)) that represents the current belief of what an unknown function looks like based on the available data samples.\n",
    "- It then uses this model to guide the optimization process by measuring the potential quality of one configuration over another, done through a heuristic called an [acquisition function](#Acquisition-Function). \n",
    "- Finally, an optimizer is used to find the configuration that will be evaluated in this round. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrogate Model\n",
    "\n",
    "Evaluating a configuration can be an expensive job. Furthermore, we do not have any information about how the actual loss will react to different hyperparameter configurations. In the context of BO, a so called surrogate model is fitted to all the previous evaluations, while an [acquisition function](#Acquisition-Function) is employed to decide which point to evaluate next according to the prediction given by the surrogate model. A surrogate model is required to give two predictions: \n",
    "- the mean of the posterior belief distribution\n",
    "- variance from this mean cross the whole space\n",
    "\n",
    "Here we provide a uniform abstract base model that can fit the given data distribution and predict the mean and variances at the target position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "np.random.seed(1)\n",
    "\n",
    "class BaseModel(object):\n",
    "    \"\"\"\n",
    "    A surrogate model is used to evaluate the potential loss distribution, and \n",
    "    so, it should be able to predict the mean and variance values on the \n",
    "    given position.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.is_trained = False\n",
    "        self.model = None\n",
    "        self.imp = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=np.finfo(float).max)\n",
    "\n",
    "    def train(self, X: np.ndarray, y: np.ndarray):\n",
    "        if len(X.shape) == 1:\n",
    "            X = X[np.newaxis, :]\n",
    "        X = self._impute_nan(X)\n",
    "        self.model.fit(X, np.squeeze(y))\n",
    "        self.is_trained = True\n",
    "\n",
    "    def predict(self, X: np.ndarray, **kwargs):\n",
    "        if len(X.shape) == 1:\n",
    "            X = X[np.newaxis, :]\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"model needs to be trained first!\")\n",
    "        \n",
    "        X = self._impute_nan(X)\n",
    "        \n",
    "        return self._predict(X, **kwargs)\n",
    "\n",
    "    def _predict(self, X: np.ndarray, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _impute_nan(self, input):\n",
    "        return self.imp.fit_transform(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We use a toy example to show how surrogate models describe the possibile distribution of the target function. First, let's generate a set of data points from a simple 1-D distribution. In this case, we use $f (x) = sin (5x) \\big ( 1 - tanh(x ^ 2) \\big )$ and then add noise to it to get our set of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    \"\"\"\n",
    "    This is a simple function that we need to approximate using a surrogate model\n",
    "    \"\"\"\n",
    "    return np.sin(5. * x) * (1. - np.tanh(x ** 2)) \n",
    "\n",
    "def noisy(y, noise_scale=0.0):\n",
    "    \"\"\"\n",
    "    We add random gaussian noise to points sampled from the function\n",
    "    \"\"\"\n",
    "    return y + np.random.normal(scale=noise_scale, size=y.shape)\n",
    "\n",
    "# Bounds of the surrogate model\n",
    "lower_sur = -2\n",
    "upper_sur = 2\n",
    "\n",
    "# create the X and Y axes\n",
    "x_sur = np.linspace(lower_sur, upper_sur, 400).reshape(-1, 1)\n",
    "fx_sur = func(x_sur)\n",
    "\n",
    "# scale for adding the noise\n",
    "noise_scale_sur = 0.2\n",
    "\n",
    "# sample 20 points between the bounds to create a training prior,\n",
    "# evaluate the function on these points, and then add noise\n",
    "x_train_sur = np.linspace(lower_sur, upper_sur, 20).reshape(-1, 1)\n",
    "y_train_sur = func(x_train_sur)\n",
    "y_train_sur = noisy(y_train_sur, noise_scale=noise_scale_sur)\n",
    "\n",
    "# sample 100 more points to test\n",
    "x_test_sur = np.linspace(lower_sur, upper_sur, 100).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "\n",
    "\n",
    "def plot_surrogate_model_regression(ax, fig, surrogate_predict_info=None):\n",
    "    ax.plot(x_sur, fx_sur, \"r--\", label=\"True (unknown)\")\n",
    "    ax.plot(x_sur, fx_sur + 1.96 * noise_scale_sur, 'y--',label='Noise Bound')\n",
    "    ax.plot(x_sur, fx_sur - 1.96 * noise_scale_sur, 'y--')\n",
    "\n",
    "    ax.plot(x_train_sur, y_train_sur, 'k*', label=\"Observations\")\n",
    "    \n",
    "    if surrogate_predict_info is not None:\n",
    "        mu_sur = surrogate_predict_info['mu']\n",
    "        var_sur = surrogate_predict_info['var']\n",
    "        std_sur = np.sqrt(var_sur)\n",
    "        \n",
    "        mu_sur = np.squeeze(mu_sur)\n",
    "        std_sur = np.squeeze(std_sur)\n",
    "\n",
    "        model_name = surrogate_predict_info['model_name']\n",
    "        ax.plot(x_test_sur, mu_sur, \"b\", label=\"predicted mean\")\n",
    "        ax.fill_between(x=np.squeeze(x_test_sur), \n",
    "                        y1=mu_sur - 1.9600 * std_sur, y2=mu_sur + 1.9600 * std_sur, \n",
    "                        alpha=.2, fc=\"b\",\n",
    "                        label=\"predicted uncertainty\")\n",
    "        ax.set_title(f'predicted result from {model_name}')\n",
    "    else:\n",
    "        ax.set_title(f\"An unknown function\")\n",
    "\n",
    "\n",
    "    ax.legend()\n",
    "    ax.plot()\n",
    "\n",
    "    \n",
    "def plot_model_prediction(model_type, model_kwargs: dict={}):\n",
    "    model_name = model_type.__name__\n",
    "    model = model_type(**model_kwargs)\n",
    "    model.train(x_train_sur, y_train_sur)\n",
    "    predicted_mean_sur, predicted_var_sur = model.predict(x_test_sur)\n",
    "\n",
    "    predict_info = {'mu': predicted_mean_sur, 'var': predicted_var_sur, 'model_name': model_name}\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plot_surrogate_mdoel_regression(ax, fig, predict_info)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plot_surrogate_model_regression(ax, fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### A dummy model\n",
    "\n",
    "We use an exemplary dummy regression model showing you how to train a surrogate model and use it to predict the potential data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "class DummyModel(BaseModel):\n",
    "    \"\"\"\n",
    "    This is only an example showing you how to implement a surrogate model\n",
    "    \"\"\"\n",
    "    def __init__(self, constant_value=0.5):\n",
    "        super(DummyModel, self).__init__()\n",
    "        self.model = DummyRegressor(strategy='constant', constant=constant_value)\n",
    "\n",
    "    def _predict(self, X: np.ndarray, **kwargs):\n",
    "        mu, std = self.model.predict(X, return_std=True)\n",
    "        return mu, std ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_prediction(DummyModel)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Gaussian Processes\n",
    "\n",
    "[Gaussian Processes](http://www.gaussianprocess.org/gpml/chapters/RW.pdf) (GPs) are one of the most popular choices of surrogate models.\n",
    "\n",
    "A GP predicts the distribution of a target point as :\n",
    "$$\n",
    "f_{\\star} \\big ( \\mathbf{X_{\\star}}, \\mathbf{X}, \\mathbf{y} \\big) \\sim \\mathcal{N} \\big(K_{*} K_y^{-1} \\mathbf{y}, \\nonumber{} K_{**} - K_{*}^T K_{y}^{-1} K_{*}\\big)\n",
    "$$\n",
    "        \n",
    "where $\\mathbf{X}$ and $\\mathbf{y}$ are the previous observed points and values, $\\mathbf{X_{\\star}}$ are the points to be evaluated. $K_{*} = k \\big(\\mathbf{X}, \\mathbf{X^\\star}\\big)$ denotes the vector of covariances between $\\mathbf{X_{\\star}}$ and all previous observations. $K_{**} = k \\big(\\mathbf{X^\\star} \\mathbf{X^\\star}\\big)$ is the covariance matrix of all previously evaluated configurations.\n",
    "\n",
    "Please follow the example given in DummyModel and implement all the related function under [Surrogate Model](#Surrogate-Model). You could use your favourite packages, e.g., [Scikit-Learn](https://scikit-learn.org/stable/), [gpytorch](https://gpytorch.ai/). \n",
    "\n",
    "\n",
    "The choice of the kernel can be seen as a prior on the form of the function to be approximated. Please try different kernels and see how the regression model changes. Please explain which kernel you would actually use in practice in the context of AutoML.\n",
    "\n",
    "After you have finished your implementation, you could plot the distribution predicted by GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import typing\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, Matern, WhiteKernel, Kernel\n",
    "\n",
    "class GaussianProcess(BaseModel):\n",
    "    # TODO implement all the functions related to a GP. You need to consider how to initialze the model and\n",
    "    # do a correct prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# After that we could plot the mean and variance values predicted by a GP model\n",
    "plot_model_prediction(GaussianProcess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Random Forest\n",
    "\n",
    "Random Forests (RF) is another popular surrogate model. RF is the ensemble of multiple regression trees. Each tree in RF gives its own prediction. The final predicted mean and variance are the empirical mean and variances of these predictions.\n",
    "\n",
    "Please build a RF model that fits the observations and predicts the mean and variance values at the quired points. You need to implement all the related function.\n",
    "   \n",
    "After you have finished your implementation, please run the code to plot the predicted distribution by RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we use the [pyrfr](https://github.com/automl/random_forest_run) package to construct a random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surrogate_model import RFR\n",
    " \n",
    "plot_model_prediction(RFR, model_kwargs={'do_bootstrapping': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now you need to implement an RF model by yourself with [Scikit-Learn](https://scikit-learn.org/stable/) and compare the predicted result with the one predicted by pyrfr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import copy\n",
    "\n",
    "class RandomForest(BaseModel):\n",
    "    # TODO implement all the functions related to a GP. \n",
    "    # You need to consider which values are required to initialze the model \n",
    "    # and make a correct prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# After that we can plot the mean and variance values predicted by a RF model\n",
    "\n",
    "plot_model_prediction(RandomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquisition Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Acquisition function $u(\\cdot)$ judges the utility (or usefulness) of evaluating $f$ at \n",
    "$\\mathbf{\\lambda}^{(t)}\\in \\mathbf{\\Lambda}$. To this end, acquisition functions trade off exploration and exploitation. Some popular examples of acquisition functions are: \n",
    "- Probability of improvement ([PI](#Probabilitiy-of-Improvement-\\(PI\\))) \n",
    "- Expected improvement ([EI](#Expected-Improvement-\\(EI\\))) \n",
    "- Lower confidence bound ([LCB](#Lower-Confidence-Bound-\\(LCB\\))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An acquisition function usually requires the following item:\n",
    "   - A surrogate model that is trained with previous evaluated data points and able to predict the mean and variance values at the target points\n",
    "   - Statistical information of the previous evaluated points (e.g., the current best evaluated values in [PI](#Probabilitiy-of-Improvement-\\(PI\\)) and [EI](#Expected-Improvement-\\(EI\\)), number of previously evaluated points in [LCB](#Lower-Confidence-Bound-\\(LCB\\)))\n",
    "   - These items need to be updated during the course of optimization (you need to specify `self._required_update` at `__init__` function)\n",
    "    \n",
    "We control the exploration-exploitation trade off with the hyperparameter assigned to the acquisition functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convert_configurations_to_array(configs: List[Configuration]):\n",
    "    return np.array([config.get_array() for config in configs], dtype=np.float64)\n",
    "\n",
    "class AbstractAcquisitionFunction(object):\n",
    "    \"\"\"\n",
    "    An acquisition function determines how good a configuration is based on the \n",
    "    predicted result of a surrogate model\n",
    "    \"\"\"\n",
    "    def __init__(self, model: BaseModel):\n",
    "        self.model = model\n",
    "        self._required_updates = ('model', )\n",
    "\n",
    "    def update(self, **kwargs: Any) -> None:\n",
    "        for key in self._required_updates:\n",
    "            if key not in kwargs:\n",
    "                raise ValueError(\n",
    "                    'Acquisition function %s needs to be updated with key %s, but only got '\n",
    "                    'keys %s.'\n",
    "                    % (self.__class__.__name__, key, list(kwargs.keys()))\n",
    "                )\n",
    "        for key in kwargs:\n",
    "            if key in self._required_updates:\n",
    "                setattr(self, key, kwargs[key])\n",
    "\n",
    "    def __call__(self, configurations: List[Configuration]) -> np.ndarray:\n",
    "        X = convert_configurations_to_array(configurations)\n",
    "        if len(X.shape) == 1:\n",
    "            X = X[np.newaxis, :]\n",
    "\n",
    "        acq = self._compute(X)\n",
    "        if np.any(np.isnan(acq)):\n",
    "            idx = np.where(np.isnan(acq))[0]\n",
    "            acq[idx] = -np.finfo(np.float).max\n",
    "        return acq\n",
    "\n",
    "    def _compute(self, X: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we will generate a set of data points. An off-the-shelf GP model will do the prediction task. You only need to focus on computing the acquisition function values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surrogate_model.gaussian_process import GaussianProcess\n",
    "from surrogate_model.random_forest import RFR\n",
    "\n",
    "# set the bounds\n",
    "lower_acq = -2\n",
    "upper_acq = 2\n",
    "\n",
    "# Create the configuration space and add hyperparameters\n",
    "cs = ConfigurationSpace(seed=1)\n",
    "cs.add_hyperparameter(UniformFloatHyperparameter(\"x\", lower=lower_acq, upper=upper_acq))\n",
    "\n",
    "# sample a configuration\n",
    "configs_train_acq = cs.sample_configuration(8)\n",
    "\n",
    "# Create traces for trainign\n",
    "x_train_acq = np.asarray([config['x'] for config in configs_train_acq])\n",
    "fx_train_acq = func(x_train_acq)\n",
    "y_train_acq = noisy(fx_train_acq, noise_scale=0.04)\n",
    "\n",
    "# Create traces for test\n",
    "x_test_acq = np.linspace(lower_acq, upper_acq, 100).reshape(-1, 1)\n",
    "configs_test_acq = [Configuration(configuration_space=cs, values={\"x\": x.item()}) for x in x_test_acq]\n",
    "fx_gt_acq = func(x_test_acq)\n",
    "\n",
    "# we use a GP model to predict the mean and variance values, feel free to use other surrogate models here\n",
    "surro_model_acq = GaussianProcess()\n",
    "surro_model_acq.train(convert_configurations_to_array(configs_train_acq), y_train_acq)\n",
    "\n",
    "mu_acq, var_acq = surro_model_acq.predict(convert_configurations_to_array(configs_test_acq))\n",
    "std_acq = np.sqrt(var_acq)\n",
    "mu_acq = np.squeeze(mu_acq)\n",
    "std_acq = np.squeeze(std_acq)\n",
    "\n",
    "\n",
    "def plot_acq_values(acq_values, fig_title='Example'):\n",
    "    \"\"\"\n",
    "    Function to plot a list of acqusition values\n",
    "    \"\"\"\n",
    "    acq_valeus_arg_max = np.argmax(acq_values)\n",
    "    plt.clf()\n",
    "    fig, axs = plt.subplots(2, 1)\n",
    "    axs[0].set_title(fig_title)\n",
    "    axs[0].plot(x_test_acq, fx_gt_acq, \"r--\", label=\"True (unknown)\")\n",
    "    axs[0].plot(x_train_acq, y_train_acq, 'k*', label=\"Observations\")\n",
    "    axs[0].plot(x_test_acq, mu_acq, \"b\", label=\"prediction\")\n",
    "    axs[0].fill_between(x=np.squeeze(x_test_acq), y1=mu_acq - 1.9600 * std_acq, y2=mu_acq + 1.9600 * std_acq, alpha=.2, fc=\"b\")\n",
    "\n",
    "    axs[1].fill_between(x=np.squeeze(x_test_acq), y1=0, y2=acq_values)\n",
    "    axs[1].plot(x_test_acq[acq_valeus_arg_max], acq_values[acq_valeus_arg_max], 'kx', label=\"maximal acq_value\")\n",
    "    axs[1].legend()\n",
    "    axs[1].set_ylabel(f\" acq_values\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    #plt.savefig(f\"{fig_title}.png\")\n",
    "    \n",
    "def plot_acq_values_wrapper(\n",
    "                acq_func_class, \n",
    "                acq_func_init_kwargs, \n",
    "                acq_func_update_kwargs, \n",
    "                fig_title='Example'\n",
    "    ):\n",
    "    \n",
    "    \"\"\"\n",
    "    Wrapper for plotting acquisition function values\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "\n",
    "    acq_func_class  \n",
    "        Class of acqusition function i.e the function definition\n",
    "    \n",
    "    acq_func_init_kwargs\n",
    "        Initial arguments required to instantiate the acquisition function object                        \n",
    "    \n",
    "    acq_func_update_kwargs\n",
    "        The parameters of the function that need to be updated on the fly \n",
    "        (each time when the model receives new data  and is retrained)\n",
    "    \n",
    "    fig_title \n",
    "        the title of the figure\n",
    "    \"\"\"\n",
    "    acq_func = acq_func_class(**acq_func_init_kwargs)\n",
    "    acq_func.update(**acq_func_update_kwargs)\n",
    "    acq_values = acq_func(configs_test_acq)\n",
    "    plot_acq_values(acq_values=acq_values, fig_title=fig_title)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### A dummy acquisition function\n",
    "\n",
    "As before, we use a dummy acqusition function showing you how to correctly update the contents of the acquisition functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DummyAcqFunc(AbstractAcquisitionFunction):\n",
    "    def __init__(self,\n",
    "                 model: BaseModel):\n",
    "        \"\"\"\n",
    "        This is only an example showing you how to correctly implement\n",
    "        acquisition functions. It returns a randomly sampled value plus the \n",
    "        mean value predicted by the model.\n",
    "\n",
    "        Thus, to compute acquisition function values correctly, you need to update \n",
    "        a new model that is fitted to the current data distribution before you can \n",
    "        actually compute the acquisitino function value\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        model \n",
    "            model to compute the data distribution\n",
    "        \n",
    "        \"\"\"\n",
    "        super(DummyAcqFunc, self).__init__(model)\n",
    "        self._required_updates = ('model',)\n",
    "    \n",
    "    \n",
    "    def _compute(self, X: np.ndarray) -> np.ndarray:\n",
    "        if len(X.shape) == 1:\n",
    "            X = X[:, np.newaxis]\n",
    "        m, _ = self.model.predict(X)\n",
    "        return np.random.randn(X.shape[0]) + m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# To compute DummyAcqFunc values, only model is required. Thus `DummyAcqFunc._required_updates \n",
    "# only requires surro_model_acq as update keys. \n",
    "dummy_init_kwargs = {'model': surro_model_acq}\n",
    "dummy_update_kwargs = {'model': surro_model_acq}\n",
    "\n",
    "plot_acq_values_wrapper(\n",
    "                DummyAcqFunc, \n",
    "                acq_func_init_kwargs=dummy_init_kwargs, \n",
    "                acq_func_update_kwargs=dummy_update_kwargs\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Improvement-based Policies\n",
    "\n",
    "Improvement-based acquisition functions select the points that are most likely to improve upon the incumbent at time step $t$ as: \n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{\\lambda}}^{(t-1)}\\in argmin_{\\mathbf{\\lambda}' \\in D^{(t-1)}}c(\\mathbf{\\lambda}')\n",
    "$$ \n",
    "\n",
    "where $c(\\lambda)$ is the cost of the hyperparameter configuration~$\\lambda$. We write $c_{inc}$ as shorthand for the cost of the current incumbent: $c_{inc} = \\min_{t' \\leq t-1} c(\\hat{\\mathbf{\\lambda}}^{(t')})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Probabilitiy of Improvement (PI)\n",
    "\n",
    "The value of the acquisition function is proportional to the probability of improvement at each point. Probability of improvement (PI) is computed by\n",
    "\n",
    "$$\n",
    "\\alpha_{PI}(\\mathbf{x}; D_n) = P \\big(c(\\mathbf{\\lambda}) \\leq c_{inc} \\big)\n",
    "$$\n",
    "\n",
    "Since the predictive distribution for $c(\\lambda)$ is a Gaussian distribution,  $\\mathcal{N} \\big(\\mu^{(t-1)}(\\mathbf{\\lambda}), {\\sigma^2}^{(t-1)}(\\mathbf{\\lambda}) \\big)$, this can be written as \n",
    "$u_{PI}^{(t)}(\\mathbf{\\lambda}) = \\Phi(Z)$, with\n",
    "\\begin{equation}\n",
    "    Z=\\frac{c_{inc} - \\mu^{(t-1)}(\\mathbf{\\lambda}) - \\xi}{\\sigma^{(t-1)}(\\mathbf{\\lambda})}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\Phi(\\cdot)$ is the CDF of the standard normal distribution and $\\xi$ is an optional exploration hyperparameter, which needs to be specified with the initialization of the acquisition function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "class PI(AbstractAcquisitionFunction):\n",
    "    #TODO: implment all the related function in PI, you need to consider which values are required for\n",
    "    # computing PI values when new data comes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO update the values that are requried by computing a PI acquisition function\n",
    "\n",
    "eta = np.min(y_train_acq)\n",
    "\n",
    "# this is the dictionary of arguments that we use to initialize\n",
    "pi_init_kwargs = {}\n",
    "\n",
    "# this is the dictionary of arguments that need to be updated\n",
    "pi_acq_update_kwargs = {}\n",
    "\n",
    "plot_acq_values_wrapper(PI, \n",
    "                        acq_func_init_kwargs=pi_init_kwargs, \n",
    "                        acq_func_update_kwargs=pi_acq_update_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Expected Improvement (EI)\n",
    "\n",
    "The value is not just proportional to the probability, but also to the magnitude of possible improvement from the point. The one-step positive improvement over the current incumbent is defined as: \n",
    "$$\n",
    "I^{(t)}(\\mathbf{\\lambda}) = \\max (0, c_{inc} - c(\\mathbf{\\lambda}))\n",
    "$$ \n",
    "\n",
    "Expected improvement (EI) is then defined as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "u_{EI}^{(t)}(\\mathbf{\\lambda})\n",
    "&= \\mathbb{E}[\\mathbf{I}^{(t)}(\\mathbf{\\lambda})] \\nonumber  \\\\\n",
    "&= \\int_{-\\infty}^{\\infty} p^{(t)}(c \\mid \\lambda) \\cdot I^{(t)}(\\lambda) \\mathrm{d} c.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Since the posterior distribution of $\\hat{c}(\\mathbf{\\lambda})$ is a Gaussian, the Expected Imporvement (EI) can be computed in closed form:\n",
    "\n",
    "$$\n",
    "{u_{EI}^{(t)}(\\mathbf{\\lambda})} =\n",
    "\\begin{cases}\n",
    "    \\sigma^{(t)}(\\mathbf{\\lambda})[Z\\Phi(Z) + \\phi(Z)], & \\text{if }\\sigma^{(t)}(\\mathbf{\\lambda}) > 0 \\\\\n",
    "    0 & \\text{if }\\sigma^{(t)}(\\mathbf{\\lambda}) = 0,\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $Z =\\dfrac{c_{inc} - \\mu^{(t)}(\\mathbf{\\lambda}) - \\xi}{\\sigma^{(t)}(\\mathbf{\\lambda})}$ and  $\\xi$  is an optional exploration hyperparameter. As in the case of PI, $\\xi$ needs to be specified with the initialization of the acquisition function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EI(AbstractAcquisitionFunction):\n",
    "        #TODO: implment all the related function in EI, you need to consider which values are required when \n",
    "        # new data comes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO update the values that are requried by computing a EI acquisition function\n",
    "\n",
    "eta = np.min(y_train_acq)\n",
    "\n",
    "ei_init_kwargs = {}\n",
    "ei_acq_update_kwargs = {}\n",
    "\n",
    "plot_acq_values_wrapper(EI, \n",
    "                        acq_func_init_kwargs=ei_init_kwargs, \n",
    "                        acq_func_update_kwargs=ei_acq_update_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Other Policies\n",
    "\n",
    "Several other acquisition functions exist that do not compute the improvement upon the current incumbent, and so, these policies require different update rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Lower  Confidence Bound (LCB)\n",
    "\n",
    "We control the exploration through the variance and control parameter and exploit the minimum values. Lower confidence Bound (LCB) is defined by:\n",
    "\n",
    "$$\n",
    "u_{LCB}^{(t)} (\\mathbf{\\lambda}) - \\alpha_t\\sigma^{(t)}(\\mathbf{\\lambda})\n",
    "$$\n",
    "\n",
    "here $\\alpha_t$ is given by:\n",
    "$\\alpha_t = \\sqrt{(2\\log (|D|t^2\\pi^2/6\\delta))}$, where $\\delta$ is a constant value controlling the exploration-exploitation behaviour, in practice, all the constant values can be merged into one single value $\\xi$ to reduce the computation overload. $|D|$ is the number of data point dimensions, $t$ is the number of evaluations, e.g. the number of data points, which needs to be updated each time when new values are observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LCB(AbstractAcquisitionFunction):\n",
    "        #TODO: implment all the related function in LCB, you need to consider which values are required when \n",
    "        # new data comes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO update the values that are requried by computing a LCB acquisition function\n",
    "\n",
    "num_data = np.shape(y_train_acq)[0]\n",
    "\n",
    "lcb_init_kwargs = {}\n",
    "lcb_acq_update_kwargs = {}\n",
    "\n",
    "plot_acq_values_wrapper(LCB, \n",
    "                        acq_func_init_kwargs=lcb_init_kwargs, \n",
    "                        acq_func_update_kwargs=lcb_acq_update_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Acquisition Function Optimizer\n",
    "\n",
    "\n",
    "In the previous section, we maximized the acquisition function by doing a grid search: this might only work well for lower dimensional space. For higher dimensional problems, we need a more advanced streagy: an acquisition function optimizer that suggests a configuration with the best acquisition function value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate 20 different configurations and store the results under ```runhistory.json```. Starting from the already evaluated configurations, we need to ask our optimizer to give suggestions to be evaluated in the next iteration. Before digging deeper into Acqusition function optimizer, first you need to complete a BO iteration described at [Bayesian Optimization](#Bayesian-Optimization).\n",
    "\n",
    "\n",
    "Just like before, we will plot the trajectory of the acquisition function, please plot all the points suggsted by the optimizer with cyan \"x\" marker and mark the point that has the largest acquisition function value (this configuration should also be the one that will be evaluated further) with black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surrogate_model.gaussian_process import GaussianProcess\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# we use EI to do illustration\n",
    "model_opt = GaussianProcess()\n",
    "acq_func = EI(model=model_opt)\n",
    "\n",
    "# previous run histoy is stored here\n",
    "rh = RunHistory()\n",
    "rh.load_json('kmnist_opt/run_0/runhistory.json', cs_lenet)\n",
    "\n",
    "# Transform rh to numpy array    \n",
    "x_cfgs, y_cfgs, previous_cfgs = collect_evaluation_info(rh)\n",
    "    \n",
    "\n",
    "# plotting information\n",
    "resolution = 150\n",
    "\n",
    "x_grid_values = np.linspace(0, 1, resolution)\n",
    "y_grid_values = np.linspace(0, 1, resolution)\n",
    "\n",
    "x_ax, y_ax = np.meshgrid(x_grid_values, y_grid_values)\n",
    "\n",
    "X_test = np.dstack([x_ax, y_ax]).reshape([-1, 2])\n",
    "\n",
    "\n",
    "# TODO finish the first two step of one BO iteration: fit a surrogate model with the previous configurations\n",
    "# and update all the information requried by computing an acquisition function\n",
    "\n",
    "\n",
    "\n",
    "def plot_acq_optimizer(acq_optimier=None, opt_kwargs={}):\n",
    "    # As before, we plot how the acq_optimizer gives the final suggestion\n",
    "    acq_grid_values = acq_func._compute(X_test).reshape([resolution, resolution])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(x_cfgs[:, 0], x_cfgs[:, 1], \"x\", color='r', markersize=3,\n",
    "            lw=0, label=\"Previous Samples\")\n",
    "    \n",
    "    if acq_optimier is not None:\n",
    "        # TODO generate all the configurations suggested by the acquisition function maximizer and store them\n",
    "        # as `cfgs_suggest`\n",
    "        cfgs_suggest = []\n",
    "        x_suggest = np.zeros([len(cfgs_suggest), len(cs_lenet.get_hyperparameters())])\n",
    "\n",
    "        for idx_cfg, cfg_suggest in enumerate(cfgs_suggest):\n",
    "            x_suggest[idx_cfg] = cfg_suggest.get_array()\n",
    "        \n",
    "        # TODO plot the configurations suggested by the optimizer\n",
    "\n",
    "\n",
    "    cm = ax.pcolormesh(x_ax, y_ax, acq_grid_values.reshape([resolution, resolution]),\n",
    "                       )\n",
    "\n",
    "    cb = fig.colorbar(cm)\n",
    "\n",
    "    plt.xlabel('batch_size')\n",
    "    plt.ylabel('learning_rate')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(type(acq_func).__name__)\n",
    "    plt.show()\n",
    "    \n",
    "plot_acq_optimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let us define an abstract class that provides a uniform API for all the optimzers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "\n",
    "class AcquisitionFunctionMaximizer(object, metaclass=abc.ABCMeta):\n",
    "    \"\"\"\n",
    "    Abstract class for acquisition maximization.\n",
    "    In order to use this class it has to be subclassed and the method\n",
    "    ``_maximize`` must be implemented.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            acquisition_function: AbstractAcquisitionFunction,\n",
    "            config_space: ConfigurationSpace,\n",
    "            rng: typing.Optional[np.random.RandomState] = None,\n",
    "    ):\n",
    "        self.acquisition_function = acquisition_function\n",
    "        self.config_space = config_space\n",
    "\n",
    "        if rng is None:\n",
    "            self.rng = np.random.RandomState(seed=1)\n",
    "        else:\n",
    "            self.rng = rng\n",
    "\n",
    "    def maximize(\n",
    "        self,\n",
    "        previous_configs: typing.List[Configuration],\n",
    "        **kwargs,\n",
    "    ) -> typing.Iterator[Configuration]:\n",
    "        \"\"\"\n",
    "        Maximize acquisition function using ``_maximize``.\n",
    "        Parameter\n",
    "        -------\n",
    "        previous_configs: List[Configuration]\n",
    "            Configurations that are evaluated in the previous runs\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        iterable\n",
    "            An iterable consisting of :class:`configspace.Configuration`.\n",
    "        \"\"\"\n",
    "        return iter([t[1] for t in self._maximize(previous_configs, **kwargs)])\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _maximize(\n",
    "            self,\n",
    "            previous_configs: typing.List[Configuration],\n",
    "            num_points: int,\n",
    "    ) -> typing.List[typing.Tuple[float, Configuration]]:\n",
    "        \"\"\"\n",
    "        Implements acquisition function maximization.\n",
    "        In contrast to ``maximize``, this method returns an iterable of tuples,\n",
    "        consisting of the acquisition function value and the configuration. This\n",
    "        allows to plug together different acquisition function maximizers.\n",
    "        Returns\n",
    "        -------\n",
    "        iterable\n",
    "            An iterable consistng of\n",
    "            tuple(acqusition_value, :class:`configspace.Configuration`).\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def _sort_configs_by_acq_value(\n",
    "            self,\n",
    "            configs: typing.List[Configuration]\n",
    "    ) -> typing.List[typing.Tuple[float, Configuration]]:\n",
    "        \"\"\"\n",
    "        Sort the given configurations by acquisition value\n",
    "        Parameters\n",
    "        ----------\n",
    "        configs : list(Configuration)\n",
    "        Returns\n",
    "        -------\n",
    "        list: (acquisition value, Candidate solutions),\n",
    "                ordered by their acquisition function value\n",
    "        \"\"\"\n",
    "        acq_values = self.acquisition_function(configs)\n",
    "\n",
    "        # From here\n",
    "        # http://stackoverflow.com/questions/20197990/how-to-make-argsort-result-to-be-random-between-equal-values\n",
    "        random = self.rng.rand(len(acq_values))\n",
    "        # Last column is primary sort key!\n",
    "        indices = np.lexsort((random.flatten(), acq_values.flatten()))\n",
    "\n",
    "        # Cannot use zip here because the indices array cannot index the\n",
    "        # rand_configs list, because the second is a pure python list\n",
    "        return [(acq_values[ind], configs[ind]) for ind in indices[::-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Optimizer\n",
    "\n",
    "Due to the [curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality), the number of points required by grid search becomes almost prohibitive under high dimensional search spaces. Furthermore, when some hyperparameters are much more important than others, random search often performs much better than grid search. Thus, random search can better solve these kinds of problems. The number of the samples is specified by the users while the configuration values of each dimension are (potentially) different. Please sample 20 points from the configuration space and plot the trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomOptimizer(AcquisitionFunctionMaximizer):\n",
    "    def _maximize(\n",
    "            self,\n",
    "            previous_configs: typing.List[Configuration],\n",
    "            num_points: int,\n",
    "    ) -> typing.List[typing.Tuple[float, Configuration]]:\n",
    "        # TODO randomly sample num_points configuratinos and then return the configurations that are sorted by their\n",
    "        # acquisition function values (You could find the corresponding function by the base Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_opt = RandomOptimizer(acquisition_function=acq_func, config_space=cs_lenet)\n",
    "opt_kwargs = {'num_points': 20}\n",
    "plot_acq_optimizer(rand_opt, opt_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobol Sequence\n",
    "\n",
    "Despite its strong performance, random search cannot guarantee that the search space is uniformly covered by the sampled points. A [Sobol Sequence](https://math.stackexchange.com/questions/888490/understanding-sobol-sequences) covers the whole search space regardless the number of the search space dimensions. Please select 1000 points of a Sobol sequence using [Scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.qmc.Sobol.html) (we want to sample an arbitrary number of points) and  plot the trajectory. You need to use the function `transform_continuous_designs` under [util](#Acquisition-Function-Optimizer) to transform teh numpy array to Configuration objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.qmc import Sobol\n",
    "\n",
    "class SobolOptimizer(AcquisitionFunctionMaximizer):\n",
    "    # TODO implement all the functions that are required to for sobol optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobol_opt = SobolOptimizer(acquisition_function=acq_func, config_space=cs_lenet)\n",
    "opt_kwargs = {'num_points': 20}\n",
    "plot_acq_optimizer(sobol_opt, opt_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Optimizer\n",
    "\n",
    "\n",
    "Global search provides a coarse estimation of the global search space. We can then fine tune the hyperparameter configurations with local search. Starting from a given set of candidates, local search iteratively moves to the neighbors of the candidates to find the optimal solutions. \n",
    "\n",
    "You can call the method `ConfigSpace.util.get_one_exchange_neighbourhood()` (you can specify the corrected values by yourself or use the function `get_one_exchange_neighbourhood()` under [util](#Acquisition-Function-Optimizer) defined below to get a one-exchange neighborhood. You should then iteratively select the neighbors that improve upon the incumbent candidates. The search stops if none of the neighbors have better acquisition values compared to the current candidates (Sometimes, it is still beneficial to make some plateau moves).\n",
    "\n",
    "Local search requires a start points. Please start from 10 previous configurations with the largest acquisition function values and do a local search starting from each point. Besides that, the user could also specify a set of points `additional_start_points` as starting points (in which case, both starting points sets contain `num_points` starting points). This time you only need to return the point suggested by each local search trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "class LocalSearchOptimizer(AcquisitionFunctionMaximizer):\n",
    "    def _maximize(\n",
    "            self,\n",
    "            previous_configs: typing.List[Configuration],\n",
    "            num_points: int,\n",
    "            additional_start_points: typing.Optional[typing.List[typing.Tuple[float, Configuration]]] = None,\n",
    "    ) -> typing.List[typing.Tuple[float, Configuration]]:\n",
    "        init_points = self._get_initial_points(num_points=10,\n",
    "                                               previous_configs=previous_configs,\n",
    "                                               additional_start_points=additional_start_points)\n",
    "        configs_acq = self._do_search(init_points)\n",
    "\n",
    "        # shuffle for random tie-break\n",
    "        self.rng.shuffle(configs_acq)\n",
    "\n",
    "        # sort according to acq value\n",
    "        configs_acq.sort(reverse=True, key=lambda x: x[0])\n",
    "        return configs_acq\n",
    "\n",
    "    def _get_initial_points(\n",
    "            self,\n",
    "            num_points: int,\n",
    "            previous_configs: typing.List[Configuration],\n",
    "            additional_start_points: typing.Optional[typing.List[typing.Tuple[float, Configuration]]],\n",
    "    ) -> typing.List[Configuration]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "        # TODO implement all the functions that are required to for sobol optimizer, you need to consider how to get the\n",
    "        # initial starting points and how to perform local search\n",
    "\n",
    "    def _do_search(\n",
    "            self,\n",
    "            start_points: typing.List[Configuration],\n",
    "    ) -> typing.List[typing.Tuple[float, Configuration]]:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_opt = LocalSearchOptimizer(acquisition_function=acq_func, config_space=cs_lenet)\n",
    "opt_kwargs = {'num_points': 10}\n",
    "plot_acq_optimizer(local_opt, opt_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global and Local Search\n",
    "\n",
    "Local search could also start from a point suggested by a global search. Please implement an algorithm that combines the global and random search, e.g. first you should use global search to select the most promising candidates, then these candidates together with the current best observations are passed as starting points to your local search algorithms. As before, `num_points` is set as 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAndLocalSerchOptimizer(AcquisitionFunctionMaximizer):\n",
    "    def __init__(\n",
    "            self,\n",
    "            acquisition_function: AbstractAcquisitionFunction,\n",
    "            config_space: ConfigurationSpace,\n",
    "            rng: typing.Union[bool, np.random.RandomState] = None,\n",
    "            global_optimizer: typing.Optional[AcquisitionFunctionMaximizer] = None,\n",
    "            local_optimizer: typing.Optional[AcquisitionFunctionMaximizer] = None,\n",
    "    ):\n",
    "        # TODO consider how to combine global and local optimizer peacefully\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_opt = GlobalAndLocalSerchOptimizer(acquisition_function=acq_func, config_space=cs_lenet)\n",
    "opt_kwargs = {'num_points': 10, 'num_points_global': 20}\n",
    "plot_acq_optimizer(local_opt, opt_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    " Finally, choose one of your acquisition functions and surrogate models to continue the hyperparameter optimization of the neural network for 5 more iterations. Plot the incumbent loss with respect to the number of evaluations (you need to plot the losses of all the previously evaluated functions). You might need some functions defined under [util](#Acquisition-Function-Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggestion: a new configuration with its evaluated cost can be added to runhistory with the following\n",
    "# examplary block:\n",
    "import time\n",
    "import copy\n",
    "from smac.tae import StatusType\n",
    "\n",
    "\n",
    "def eval_cfg_with_time_info(cfg_lenet):\n",
    "    time_start = time.time()\n",
    "    val_score = evaluator.eval_config(cfg_lenet)\n",
    "    time_end = time.time()\n",
    "    return val_score, time_end - time_start\n",
    "\n",
    "\"\"\"\n",
    "# The following code is only an example showing how to add new run results to the runhistory\n",
    "\n",
    "# we don't want to add this cfg to the raw runhistory\n",
    "rh_copy = copy.deepcopy(rh)\n",
    "\n",
    "cfg_random = cs_lenet.sample_configuration()\n",
    "val_score, uses_time = eval_cfg_with_time_info(cfg_random)\n",
    "\n",
    "\n",
    "rh_copy.add(cfg_random, val_score, uses_time, StatusType.SUCCESS)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_bayesian_optimization(target_func: typing.Callable,\n",
    "                             rh: RunHistory,\n",
    "                             config_space: ConfigurationSpace,\n",
    "                             model: typing.Optional[BaseModel]=None,\n",
    "                             acq_func: typing.Optional[AbstractAcquisitionFunction]=None,\n",
    "                             acq_optimizer:typing.Optional[AcquisitionFunctionMaximizer]=None) -> RunHistory:\n",
    "\n",
    "    if model is None:\n",
    "        model = GaussianProcess()\n",
    "    if acq_func is None:\n",
    "        acq_func = EI(model)\n",
    "    if acq_optimizer is None:\n",
    "        acq_optimizer = GlobalAndLocalSerchOptimizer(acquisition_function=acq_func, config_space=config_space)\n",
    "    \n",
    "    if isinstance(acq_optimizer, (RandomOptimizer, SobolOptimizer)):\n",
    "        optimizer_kwargs = {\"num_points\": 1000} \n",
    "    elif isinstance(acq_optimizer, LocalSearchOptimizer):\n",
    "        optimizer_kwargs = {\"num_points\": 10} \n",
    "    elif isinstance(acq_optimizer, GlobalAndLocalSerchOptimizer):\n",
    "        optimizer_kwargs = {\"num_points\": 10, \"num_points_global\": 1000} \n",
    "    else: raise ValueError(f'Unsupported type of acq_optimizer: {acq_optimizer}')\n",
    "\n",
    "    \n",
    "    for _ in range(5):\n",
    "        # TODO implement a full BO loop here\n",
    "        raise NotImplementedError\n",
    "    return rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh = do_bayesian_optimization(target_func=eval_cfg_with_time_info, \n",
    "                              rh=rh,\n",
    "                              config_space=cs_lenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, y, _ = collect_evaluation_info(rh)\n",
    "\n",
    "\n",
    "# TODO: Plot the incumbent loss values\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LabAML",
   "language": "python",
   "name": "labaml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
